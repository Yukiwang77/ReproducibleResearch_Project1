cutpoints <- quantile(diamonds$carat, seq(0,1,length = 4), na.rm = TRUE)
cutpoints
diamonds$car2 <- cut(diamonds$carat, cutpoints)
g <- ggplot(diamonds, aes(depth, price))
g + geom_point(alpha = 1/3)+facet_grid(cut~car2)
diamonds(myd, )
diamonds[myd, ]
g + geom_point(alpha = 1/3)+facet_grid(cut~car2)+geom_smooth(method = "lm",size = 3, color = "pink")
g <- ggplot(diamonds, aes(carat, price))
ggplot(diamonds, aes(carat, price))+geom_boxplot()+facet_grid(.~cut)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?trellis.par.set
library(datasets)
data(airquality)
qplot(Wind, Ozone, data= airquality, facets = .~factor(month.abb))
qplot(Wind, Ozone, data= airquality, facets = .~factor(Month))
?geom
qplot(votes, rating, data = movies) + geom_smooth()
library(ggplot2)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies)
qplot(Wind, Ozone, data = airquality) + geom_smooth()
qplot(Wind, Ozone, data = airquality, smooth = "loess")
qplot(Wind, Ozone, data = airquality, stats_smooth = "loess")
qplot(Wind, Ozone, data = airquality) + stats_smooth("loess")
?strsplit
?unlist
?strsplit
install.packages("impute")
install.packages("impute")
library(swirl)
swirl()
head(dataMatrix)
heatmap(dataMatrix)
myedit("addPatt.R"")
myedit("addPatt.R")
myedit("addPatt.R")
source("addPatt.R", local = TRUE)
heatmap(dataMatrix)
mat
svd(mat)
matu*diag*t(matv)
matu%*%diag%*%t(matv)
svd(scale(mat))
prcomp(scale(mat))
scale(mat)
sdv1$v[ ,1]
svd1$v[ ,1]
svd$d
svd1$d
head(constantMatrix)
svd2$d
svd2$v[, 1:2]
svd2$d
dim(faceData)
a1 <- (svd1$u[ ,1] %*% svd1$d[1])%*%t(svd1$v[ , 1])
a1 <- (svd1$u[ ,1] * svd1$d[1])%*%t(svd1$v[ , 1])
image(a1)
myImage(a1)
a2 <- svd1$u[ , 1:2] %*% svd1$d[1:2] %*% t(svd1$v[, 1:2])
a2 <- svd1$u[ , 1:2] %*% diag(svd1$d[1:2]) %*% t(svd1$v[, 1:2])
myImage(a2)
myImage(svd1$u[ , 1:5] %*% diag(svd1$d[1:5]) %*% t(svd1$v[, 1:5])
)
myImage(svd1$u[ , 1:10] %*% diag(svd1$d[1:10]) %*% t(svd1$v[, 1:10]))
dim(ssd)
names(ssd)[562:563]
names(ssd[562:563])
table(ssd$subject)
sum(table(ssd$subject))
table(ssd$activity)
sub1 <- subset(ssd, subject == 1)
dim(sub1)
names(sub1[1:12])
myedit("showXY.R")
showMe(sub1[1:6])
showMe(1:6)
mdist <- dist(sub1[, 1:3])
hclust(mdist)
hclusting <- hclust(mdist)
hclustering <- hclust(mdist)
myplclust(hclustering, lab.col = unclass(sub1$activity))
mdist <- dist(sub1[, 10:12])
hclustering <- hclust(mdist)
myplclust(hclustering, lab.col = unclass(sub1$activity))
svd1 <- svd(scale(sub1[, -c(562, 563)]))
dim(svd1$u)
maxCon <- which.max(svd1$v[,2])
mdist <- dist(sub1[, 10:12], maxCon)
mdist <- dist(cbind(sub1[, 10:12], maxCon))
mdist <- dist(cbind(sub1[, 10:12, maxCon]))
mdist <- dist(sub1[, 10:12, maxCon)])
mdist <- dist(sub1[, c(10:12, maxCon)])
hclustering <- hclust(mdist)
myplclust(hclustering, lab.col = unclass(sub1$activity))
names(sub1[maxCon])
kClust <- kmeans(sub1[, -c(562:563)], centers = 6)
table(kClust$cluster, sub1$activity)
kClust <- kmeans(sub1[, -c(562:563)], centers = 6, nstart = 100)
table(kClust$cluster, sub1$activity)
dim(kClust$centers)
laying <- kClust$size==29
laying <- which(kClust$size==29)
ploat(kClust$centers[laying, 1:12], pch = 19, ylab = "Laying Cluster")
plot(kClust$centers[laying, 1:12], pch = 19, ylab = "Laying Cluster")
names(sub1[1:3])
walkdown <- which(kClust$size == 9)
walkdown <- which(kClust$size == 49)
plot(kClust$centers[walkdown, 1:12], pch = 19, ylab = "Walkdown Cluster")
#list of required packages
libraries               <- c('rJava', 'RJDBC', 'WriteXLS', 'xlsx', 'sqldf', 'zoo', 'gsubfn', 'proto', 'RSQLite', 'lubridate', 'reshape', 'reshape2', 'doBy')
#library install/load function
load_libs               <- function(libs, inst){
if(inst){
install.packages(libraries)
}
for(lib in libraries){
eval(parse(text = paste('library(', lib, ')', sep = '')))
}
}
#load/install required packages.  set second argument to TRUE if package installation is needed
load_libs(libraries, TRUE)
install.packages("xlsx")
#list of required packages
libraries               <- c('rJava', 'RJDBC', 'WriteXLS', 'xlsx', 'sqldf', 'zoo', 'gsubfn', 'proto', 'RSQLite', 'lubridate', 'reshape', 'reshape2', 'doBy')
#library install/load function
load_libs               <- function(libs, inst){
if(inst){
install.packages(libraries)
}
for(lib in libraries){
eval(parse(text = paste('library(', lib, ')', sep = '')))
}
}
#load/install required packages.  set second argument to TRUE if package installation is needed
load_libs(libraries, TRUE)
install.packages(libraries)
installed.packages("RJDBC")
remove.packages("rJava", lib="~/Library/R/3.3/library")
install.packages("rJava", type="source", repos="http://cran.us.r-project.org")
library("rJava"); .jinit(); .jcall("java/lang/System", "S", "getProperty", "java.runtime.version")
require(RJDBC)
aggrap_connect          <-      function(usn = "dashbusr", pwd = "id4d#sbd"){
vertica_driver    <-      'com.vertica.jdbc.Driver'
driver_path       <-      paste('//10.252.211.47/share47/Vertica/Vertica 6.1 Drivers/', 'vertica-jdk5-6.1.3-0.jar', sep = '')
drv               <-      JDBC(vertica_driver, driver_path, identifier.quote = "'")
cx_str            <-      "jdbc:vertica://aggdmrapdb-wc-a03.sys.comcast.net:5433/aggRAP"
aggrap            <-      dbConnect(drv, cx_str, usn, pwd)
return(aggrap)
}
aggrap                  <-      aggrap_connect("dashbusr", "id4d#sbd")
require(rJava)
library("rJava", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
require(rJava)
library("rJava", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
d <- as.Date("12-31-2016", "mmddyyyy")
D
d
d <- as.Date("12-31-2016")
d <- as.Date("12-31-2016", "mm:dd:yyyy")
d
d <- as.Date("12-31-2016", "%m-%d-%y")
d
d <- as.Date("12-31-2016", "%m-%d-%Y")
d
today()
Sys.Date()
Sys.Date()-d
#Download packages and open query connection##########################################################
rm(list=ls())
options(java.parameters = "-Xmx16000m") #allocate memory in case of out of memory issues
#Load packages (must install if not already)
#library(RODBC)
library(plyr)
# library(xlsx)
library(dplyr)
library(tidyr)
library(reshape2)
library(stringr)
#Set location for Excel Output (must change to your WD)
#Query data----------------------------------------------------------------------------------------------------
# #Open aggrap connection (first input must change depending on the name of your ODBC aggrap connection)
#Set up assumed input parameters from Unified Demand Model and assumptions----------------------------------------------------------------
#Read in assumptions from UDM/AM
#UDM_assumptions <- read.csv('UDM output.csv')
UDM_assumptions <- knime.in
scenario <- UDM_assumptions[1,"Scenario"]
UDM_assumptions <- subset(UDM_assumptions, Product =='X1 VOD' & Product_Type == 'Primary Screen' & Assumption %in% c('Bandwidth Per Device','STB','Peak Concurrency'))
UDM_assumptions <- reshape(UDM_assumptions,
timevar = "Target_Year",
idvar = c("Model_Case", "Business_Category", "Traffic_Direction", "Platform", "Assumption", "Unit","Unit_Measurement",
"Service","Service_Type","Product","Product_Type","Feature","Scenario"),
direction = "wide")
UDM_assumptions <- UDM_assumptions[,c(5,14:ncol(UDM_assumptions))]
UDM_assumptions[is.na(UDM_assumptions)] <- 0
UDM_assumptions <- aggregate(UDM_assumptions[,2:ncol(UDM_assumptions)],by=list(Assumption=UDM_assumptions$Assumption),FUN=max)
rownames(UDM_assumptions) <- UDM_assumptions$Assumption
#Assumptions made that did not come from the unified demand model
QAM_capacity <- 38.8
QAM_utilization <- 0.8
#Build Migration Data excel Sheet#####################################################################################
VodMigData <- VodMigData[,c(2,3,4,5,6,7,8,9,14,10,13)] #Set up data frame of queried data
VodMigData[is.na(VodMigData)] <- 0
t<- sapply(VodMigData, is.factor)
VodMigData[t] <- lapply(VodMigData[t], as.character)
#Set up totals of variables from queried VodMigData
Total_Service_Group_Capacity <- sum(VodMigData$Service_Group_Capacity)
Total_Peak_Demand <- sum(VodMigData$Peak_Demand)
Total_Peak_X1_Demand <- sum(VodMigData$Peak_X1_Demand)
#Start Column calculations using queried data and assumed input parameters
VodMigData <- transform(VodMigData, 'Percent_SG_demand_vs_total' = (VodMigData$Peak_X1_Demand/Total_Peak_X1_Demand))
for (i in 1:4){
assign(paste("X1_Subs_on_SG",i,sep = "."),VodMigData[,'Percent_SG_demand_vs_total']*(UDM_assumptions["STB",i+1]))
}
X1_Subs_on_SG <- data.frame(`X1_Subs_on_SG.1`,`X1_Subs_on_SG.2`,`X1_Subs_on_SG.3`, `X1_Subs_on_SG.4`)
VodMigData <- transform(merge(VodMigData,X1_Subs_on_SG, by =0 ,all=T), row.names=Row.names, Row.names=NULL)
rownames(VodMigData) <- 1:nrow(VodMigData)
for (i in 2:4){
assign(paste("QAM_Mbps_Red",i,sep = "."),(VodMigData[,i+12]-VodMigData[,i+11])*UDM_assumptions["Bandwidth Per Device",i+1]*UDM_assumptions["Peak Concurrency",i+1])
}
QAM_Mbps_Red <- data.frame(`QAM_Mbps_Red.2`,`QAM_Mbps_Red.3`,`QAM_Mbps_Red.4`)
VodMigData <- transform(merge(VodMigData,QAM_Mbps_Red, by =0 ,all=T), row.names=Row.names, Row.names=NULL)
VodMigData[is.na(VodMigData)] <- 0
VodMigData <- transform(VodMigData,'QAM_Traffic.2' = ifelse(VodMigData$Peak_Demand-VodMigData$QAM_Mbps_Red.2>=0,
VodMigData$Peak_Demand-VodMigData$QAM_Mbps_Red.2,0))
VodMigData <- transform(VodMigData,'QAM_Traffic.3' = ifelse(VodMigData$QAM_Traffic.2-VodMigData$QAM_Mbps_Red.3>=0,
VodMigData$QAM_Traffic.2-VodMigData$QAM_Mbps_Red.3,0))
VodMigData <- transform(VodMigData,'QAM_Traffic.4' = ifelse(VodMigData$QAM_Traffic.3-VodMigData$QAM_Mbps_Red.4>=0,
VodMigData$QAM_Traffic.3-VodMigData$QAM_Mbps_Red.4,0))
#Calculate QAM Reclaims per year as well as a place holder data frame with mbps difference from QAM reduction
VodMigData <- transform(VodMigData,'QAM_Reclaims.2'=ifelse(VodMigData$Peak_X1_Demand != 0 & VodMigData$QAM_Traffic.2 != 0,
floor((VodMigData$QAM_Mbps_Red.2)/QAM_capacity/2)*2,0))
VodMigData <- transform(VodMigData,'Mbps_Carryover.2'= VodMigData$QAM_Mbps_Red.2 - ifelse(VodMigData$QAM_Reclaims.2 != 0,
VodMigData$QAM_Reclaims.2*38.8,0))
VodMigData <- transform(VodMigData,'QAM_Reclaims.3'=ifelse(VodMigData$Peak_X1_Demand != 0 & VodMigData$QAM_Traffic.3 != 0,
floor((VodMigData$Mbps_Carryover.2+VodMigData$QAM_Mbps_Red.3)
/QAM_capacity/2)*2,0))
VodMigData <- transform(VodMigData,'Mbps_Carryover.3'= (VodMigData$QAM_Mbps_Red.3+VodMigData$Mbps_Carryover.2) - ifelse(VodMigData$QAM_Reclaims.3 != 0,
VodMigData$QAM_Reclaims.3*38.8,0))
VodMigData <- transform(VodMigData,'QAM_Reclaims.4'=ifelse(VodMigData$Peak_X1_Demand != 0 & VodMigData$QAM_Traffic.4 != 0,
floor((VodMigData$Mbps_Carryover.3+VodMigData$QAM_Mbps_Red.4)
/QAM_capacity/2)*2,0))
VodMigData <- transform(VodMigData,'Mbps_Carryover.4'= (VodMigData$QAM_Mbps_Red.4+VodMigData$Mbps_Carryover.3) - ifelse(VodMigData$QAM_Reclaims.4 != 0,
VodMigData$QAM_Reclaims.4*38.8,0))
#Calculate QAM Counts per year
VodMigData <- transform(VodMigData,'QAM_Count.1' = ceiling((ifelse(VodMigData$Service_Group_Capacity > 0 & VodMigData$Service_Group_Capacity/38.8>8,
floor(VodMigData$Service_Group_Capacity/38.8),
ifelse(VodMigData$Peak_Demand/38.8 > 8,ceiling(VodMigData$Peak_Demand/38.8),8)))/2)*2)
VodMigData <- transform(VodMigData,'QAM_Count.2' = ceiling((ifelse((VodMigData$QAM_Count.1-VodMigData$QAM_Reclaims.2)<=0,0,
VodMigData$QAM_Count.1-VodMigData$QAM_Reclaims.2))/2)*2)
VodMigData <- transform(VodMigData,'QAM_Count.3' = ceiling((ifelse((VodMigData$QAM_Count.2-VodMigData$QAM_Reclaims.3)<=0,0,
VodMigData$QAM_Count.2-VodMigData$QAM_Reclaims.3))/2)*2)
VodMigData <- transform(VodMigData,'QAM_Count.4' = ceiling((ifelse((VodMigData$QAM_Count.3-VodMigData$QAM_Reclaims.4)<=0,0,
VodMigData$QAM_Count.3-VodMigData$QAM_Reclaims.4))/2)*2)
rownames(VodMigData) <- 1:nrow(VodMigData)
for (i in 2:4){
assign(paste("QAM_Util",i,sep = "."),VodMigData[,i+18]/VodMigData[,i+28]/38.8)
}
QAM_Util <- data.frame(`QAM_Util.2`,`QAM_Util.3`,`QAM_Util.4`)
VodMigData <- transform(merge(VodMigData,QAM_Util, by =0 ,all=T), row.names=Row.names, Row.names=NULL)
VodMigData <- transform(VodMigData, 'QAM_Util.1' = VodMigData$Peak_Demand/QAM_Count.1/38.8)
#Remove NA and infinites
VodMigData[is.na(VodMigData)] <- 0
VodMigData[VodMigData==Inf] <- 0
VodMigData <- VodMigData[,-grep("Carryover",colnames(VodMigData))]
#Reshape the data frame from wide to long
VodMigData <- melt(VodMigData, id = c("Division","Region","System","Site_id","Peer_Group_id","Service_Group_id",
"Service_Group_Capacity","Peak_Demand","Peak_X1_Streams","Peak_Streams","Peak_X1_Demand","Percent_SG_demand_vs_total"))
strsplit <- str_split_fixed(VodMigData$variable,"\\.",2)
VodMigData <- transform(merge(VodMigData,strsplit, by =0 ,all=T), row.names=Row.names, Row.names=NULL)
colnames(VodMigData)[15:16] <- c("Variable","Year")
VodMigData$variable <- NULL
#Place scenario column into data frame
VodMigData$scenario <- rep(scenario,nrow(VodMigData))
#Remove first year data (if year is past)
#VodMigData[VodMigData$year != 1,c('Service_Group_Capacity','Peak_Demand','Peak_X1_Streams','Peak_Streams','Peak_X1_Demand','Percent_SG_demand_vs_total')] <- NA
#extract years from UDM output
years <- as.data.frame(colnames(UDM_assumptions))
years <- str_split_fixed(years$`colnames(UDM_assumptions)`,"\\.",2)
years <- as.data.frame(years[,2])
years <- as.data.frame(years[!(is.na(years) | years==""), ])
colnames(years) <- "year"
years$index <- rownames(years)
VodMigData$Year <- as.numeric(as.character(VodMigData$Year))
VodMigData <- merge(VodMigData,years, by.x = "Year", by.y = "index", all.x=T)
knime.out<-VodMigData
install.packages("tidyr")
library(boxr)
box_auth(
client_id = 'vd00pwimq2qnwhfanxe9yu283nfbykbe',
client_secret = 'OMHrDtHq1Hz8WjalhUkLZNYQPyyq1S44'
)
?grepl
installed.package
installed.package("boxr")
library(lubridate)
year()
boxr
?boxr
install.packages("R.utils")
library("RJDBC", lib.loc="~/Library/R/3.3/library")
Sys.Date()
Sys.Date()+25
Sys.Date()+23
Sys.Date()+22
Sys.Date()+19
Sys.Date()
Sys.Date()+18
round()
round(4.55)
install.packages("searchable")
aa <- c("Bandwidth per Device", "adddd", "stb", "aaaa")
startsWith(aa, "band")
?startsWith
a <- c(1:5)
b <- c(6:10)
aa <- as.data.frame(rbind(a, b))
c <- c(4:9)
aa <- as.data.frame(rbind(a, b,c))
c <- c(4:8)
aa <- as.data.frame(rbind(a, b,c))
aa[, c(1,3,2)]
aa[, paste("ss", "1", sep = ".")] <- 1
aa
?sort
library(dplyr)
aa<- c("a", "B", "D", "e")
bb <- c(1:4)
cbind(aa, bb)
cc <- cbind(aa, bb)
cc <- as.data.frame(cbind(aa, bb))
cc
arrange(cc, aa)
library(tidyr)
gather(cc, 1:2)
gather(cc, 'col', 'val',1:2)
aa.2016 <- c(1:10)
bb.2017 <- c(2:11)
df <- as.data.frame(cbind(aa.2016, bb.2017))
df
require(tidyr)
gather(df, 'col', 'value', 1:2)
df1 <- gather(df, 'col', 'value', 1:2)
separate(df1, col, into = c('type', ))
separate(df1, col, into = c('type', 'year'), sep = ".")
?separate
separate(df1, col, into = c('type', 'year'), sep = "\\.")
?paste
install.packages("tools")
install.packages("tools")
install.packages("tools")
install.packages("tools")
install.packages("tools")
install.packages("Hmisc")
install.packages("scales")
install.packages("rJava")
install.packages("RJDBC")
install.packages("WriteXLS")
install.packages("xlxs")
install.packages("xlsx")
install.packages("sqldf")
install.packages("zoo")
install.packages("gsufn")
install.packages("proto")
install.packages("RSQLite")
install.packages("reshape")
install.packages("reshape2")
install.packages("doBy")
install.packages("DBI")
install.packages("pracma")
install.packages("data.table")
install.packages("tcltk")
install.packages("foreach")
install.packages("doParallel")
install.packages("parallel")
install.packages("sendmailR")
library(xlsx)
library(WriteXLS)
install.packages("lazyeval")
install.packages("ggplot2")
Sys.Date()
as.date('2016-11-19')
Sys.Date()-20
Sys.Date()-25
Sys.Date()-28
a <- '112.0'
grep(".",a)
grepl(".",a)
which(grepl(".",a))
which(grepl(".",a))
regexpr(".",a)
gregexpr(".",a)
sub(".0","",a)
?grepl
Med <- read.csv("./Documents/DataScience/ReproducibleResearch/WK1/Medical expense.csv", header = TRUE, sep = ",")
NY.Med <- subset(Med, Med$Provider.State == "NY")
graph <- ggplot(NY.Med, aes(log(Average.Covered.Charges), log(Average.Total.Payments)))
graph + geom_point(color = "black", size = 2, alpha = 0.5) + labs(title = "Relationship Between Mean Covered Charges and Mean Total Payments") + labs(x="Log of Mean Total Payments", y = "Log of Mean Covered Charges") + geom_smooth(method = "lm")
library(ggplot2)
NY.Med <- subset(Med, Med$Provider.State == "NY")
graph <- ggplot(NY.Med, aes(log(Average.Covered.Charges), log(Average.Total.Payments)))
graph + geom_point(color = "black", size = 2, alpha = 0.5) + labs(title = "Relationship Between Mean Covered Charges and Mean Total Payments") + labs(x="Log of Mean Total Payments", y = "Log of Mean Covered Charges") + geom_smooth(method = "lm")
ggsave("./Documents/DataScience/ReproducibleResearch/WK1/plot1.pdf", plot = last_plot(), scale = 1)
ggsave("./Documents/DataScience/ReproducibleResearch/WK1/plot1.pdf", plot = last_plot(), scale = 1, width = 7, height = 9)
graph <- ggplot(Med, aes(x = log(Average.Covered.Charges), y = log(Average.Total.Payments), colour = DRG.Definition))
graph + geom_point(alpha = 0.5) + geom_smooth(method = "lm", colour = "black") + facet_grid(DRG.Definition ~ Provider.State) + labs(title = "Relationship Between Mean Covered Charges and Mean Total Payments by DRG.Definition by State") + labs(x="Log of Mean Total Payments", y = "Log of Mean Covered Charges") + theme(legend.position = "bottom")
graph <- ggplot(Med, aes(x = log(Average.Covered.Charges), y = log(Average.Total.Payments), colour = DRG.Definition))
graph + geom_point(alpha = 0.5) + geom_smooth(method = "lm", colour = "black") + facet_grid(Provider.State ~ DRG.Definition) + labs(title = "Relationship Between Mean Covered Charges and Mean Total Payments by DRG.Definition by State") + labs(x="Log of Mean Total Payments", y = "Log of Mean Covered Charges") + theme(legend.position = "bottom")
ggsave("./Documents/DataScience/ReproducibleResearch/WK1/plot2.pdf", plot = last_plot(), scale = 1, width = 16, height = 9)
str(Med)
graph <- ggplot(Med, aes(x = log(Average.Covered.Charges), y = log(Average.Total.Payments), colour = DRG.Definition))
graph + geom_point(alpha = 0.5) + geom_smooth(method = "lm", colour = "black") + facet_grid(Provider.State ~ substr(as.character(DRG.Definition), 1, 3) + labs(title = "Relationship Between Mean Covered Charges and Mean Total Payments by DRG.Definition by State") + labs(x="Log of Mean Total Payments", y = "Log of Mean Covered Charges") + theme(legend.position = "bottom")
)
Med$DRG <- substr(as.character(Med$DRG.Definition), 1, 3)
str(Med)
graph <- ggplot(Med, aes(x = log(Average.Covered.Charges), y = log(Average.Total.Payments), colour = DRG.Definition))
graph + geom_point(alpha = 0.5) + geom_smooth(method = "lm", colour = "black") + facet_grid(Provider.State ~ DRG + labs(title = "Relationship Between Mean Covered Charges and Mean Total Payments by DRG.Definition by State") + labs(x="Log of Mean Total Payments", y = "Log of Mean Covered Charges") + theme(legend.position = "bottom")
graph <- ggplot(Med, aes(x = log(Average.Covered.Charges), y = log(Average.Total.Payments), colour = DRG.Definition))
graph + geom_point(alpha = 0.5) + geom_smooth(method = "lm", colour = "black") + facet_grid(Provider.State ~ DRG) + labs(title = "Relationship Between Mean Covered Charges and Mean Total Payments by DRG.Definition by State") + labs(x="Log of Mean Total Payments", y = "Log of Mean Covered Charges") + theme(legend.position = "bottom")
graph <- ggplot(Med, aes(x = log(Average.Covered.Charges), y = log(Average.Total.Payments), colour = DRG.Definition))
graph + geom_point(alpha = 0.5) + geom_smooth(method = "lm", colour = "black") + facet_grid(Provider.State ~ substr(as.character(DRG.Definition), 1, 3)) + labs(title = "Relationship Between Mean Covered Charges and Mean Total Payments by DRG.Definition by State") + labs(x="Log of Mean Total Payments", y = "Log of Mean Covered Charges") + theme(legend.position = "bottom")
graph <- ggplot(Med, aes(x = log(Average.Covered.Charges), y = log(Average.Total.Payments), colour = DRG.Definition))
graph + geom_point(alpha = 0.5) + geom_smooth(method = "lm", colour = "black") + facet_grid(substr(as.character(DRG.Definition), 1, 3) ~ Provider.State) + labs(title = "Relationship Between Mean Covered Charges and Mean Total Payments by DRG.Definition by State") + labs(x="Log of Mean Total Payments", y = "Log of Mean Covered Charges") + theme(legend.position = "bottom")
ggsave("./Documents/DataScience/ReproducibleResearch/WK1/plot2.pdf", plot = last_plot(), scale = 1, width = 20, height = 12)
graph + geom_point(alpha = 0.5) + geom_smooth(method = "lm", colour = "black") + facet_grid(Provider.State ~ substr(as.character(DRG.Definition), 1, 3)) + labs(title = "Relationship Between Mean Covered Charges and Mean Total Payments by DRG.Definition by State") + labs(x="Log of Mean Total Payments", y = "Log of Mean Covered Charges") + theme(legend.position = "bottom")
ggsave("./Documents/DataScience/ReproducibleResearch/WK1/plot2.pdf", plot = last_plot(), scale = 1, width = 25, height = 16)
ggsave("./Documents/DataScience/ReproducibleResearch/WK1/plot2.pdf", plot = last_plot(), scale = 1.5, width = 25, height = 16)
ggsave("./Documents/DataScience/ReproducibleResearch/WK1/plot2.pdf", plot = last_plot(), scale = 0.5, width = 25, height = 16)
ggsave("./Documents/DataScience/ReproducibleResearch/WK1/plot2.pdf", plot = last_plot(), scale = 0.75, width = 25, height = 16)
ggsave("./Documents/DataScience/ReproducibleResearch/WK1/plot2.pdf", plot = last_plot(), scale = 0.75, width = 20, height = 12)
ggsave("./Documents/DataScience/ReproducibleResearch/WK1/plot2.pdf", plot = last_plot(), scale = 0.8, width = 20, height = 12)
ggsave("./Documents/DataScience/ReproducibleResearch/WK1/plot2.pdf", plot = last_plot(), scale = 1, width = 20, height = 12)
ggsave("./Documents/DataScience/ReproducibleResearch/WK1/plot2.pdf", plot = last_plot(), scale = 1, width = 20, height = 12)
?aggregate
getwd()
setwd("./Documents/DataScience/ReproducibleResearch/WK2")
install.packages("rms")
library(rms)
data <- read.csv("activity.csv", header = TRUE, sep = ",")
ImpData <- mice(data, m = 5, maxit = 10, meth = 'pmm')
library(mice)
ImpData <- mice(data, m = 5, maxit = 10, meth = 'pmm')
install.packages(mice)
install.packages("mice")
install.packages("mice")
ImpData <- mice(data, m = 1, meth = 'pmm')
library(mice)
ImpData <- mice(data, m = 1, meth = 'pmm')
str(ImpData)
head(ImpData)
totaldata <- complete(Impdata, 1)
totaldata <- complete(ImpData, 1)
head(data)
head(totaldata)
str(data)
data$date <- as.Date(data$date, format = "%Y-%m-%d")
str(data)
ImpData <- mice(data, m = 1, meth = 'pmm')
CompData$DayType <- ifelse(weekdays(CompData$date) %in% c("Saturday", "Sunday"), "Weekend", "Weekday")
data$date <- as.factor(data$date)
ImpData <- mice(data, m = 1, meth = 'pmm')
CompData <- complete(ImpData)
CompData$DayType <- ifelse(weekdays(CompData$date) %in% c("Saturday", "Sunday"), "Weekend", "Weekday")
CompData$date <- as.Date(CompData$date, format = "%Y-%m-%d")
CompData$DayType <- ifelse(weekdays(CompData$date) %in% c("Saturday", "Sunday"), "Weekend", "Weekday")
CompInterval <- aggregate( steps ~ interval, data = CompData, FUN = mean)
IntervalPlot <- ggplot(CompInterval, aes( x = interval, y = steps, color = DayType))
library(ggplot1)
library(ggplot2)
IntervalPlot <- ggplot(CompInterval, aes( x = interval, y = steps, color = DayType))
IntervalPlot + geom_line(size = 3, alpha = 0.75) + facet_wrap(~DayType) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
IntervalPlot + geom_line(size = 3, alpha = 0.75) + facet_wrap( .~ DayType) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
IntervalPlot + geom_line(size = 3, alpha = 0.75) + facet_grid( .~ DayType) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
IntervalPlot + geom_line(size = 3, alpha = 0.75) + facet_grid(. ~ DayType) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
IntervalPlot <- ggplot(CompInterval, aes( x = interval, y = steps))
IntervalPlot + geom_line(size = 3, alpha = 0.75) + facet_grid(. ~ DayType) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
head(CompData)
IntervalPlot + geom_line(size = 3, alpha = 0.75) + facet_wrap( ~ DayType) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
str(CompData)
CompData$DayType <- as.factor(CompData$DataType)
CompData$DayType <- as.factor(CompData$DayType)
IntervalPlot + geom_line(size = 3, alpha = 0.75) + facet_wrap( ~ DayType) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
IntervalPlot + geom_line(size = 3, alpha = 0.75) + facet_grid(. ~ DayType) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
IntervalPlot + geom_line(size = 3, alpha = 0.75) + facet_wrap( ~ DayType, ncol = 1, nrow = 2) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
md.pattern(CompData)
IntervalPlot + geom_line(size = 3, alpha = 0.75) + facet_wrap( ~DayType, ncol = 1, nrow = 2) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
IntervalPlot + geom_line(size = 3, alpha = 0.75) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
IntervalPlot <- ggplot(CompInterval, aes( x = interval, y = steps, color = DayType))
IntervalPlot + geom_line(size = 1, alpha = 0.75) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
str(CompInterval)
CompInterval <- aggregate( steps ~ c(interval, DayType), data = CompData, FUN = mean)
CompInterval <- CompData %>%
group_by(interval, DayType) %>%
summarize(IntervalAvg = mean(steps))
IntervalPlot <- ggplot(CompInterval, aes( x = interval, y = IntervalAvg, color = DayType))
IntervalPlot + geom_line(size = 3, alpha = 0.75) + facet_grid(. ~DayType) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
library(dplyr)
CompInterval <- CompData %>%
group_by(interval, DayType) %>%
summarize(IntervalAvg = mean(steps))
IntervalPlot <- ggplot(CompInterval, aes( x = interval, y = IntervalAvg, color = DayType))
IntervalPlot + geom_line(size = 3, alpha = 0.75) + facet_grid(. ~DayType) + labs(title = "Daily Average Steps Activity Pattern (Weekday and Weekend)", x= "5-minute Time Interval", y = "Average Steps")
green4
green4("aa")
install.packages("rmarkdown")
install.packages("rmarkdown")
getwd()
setwd("./Project1")
knitr::knit("Project1.Rmd")
knitr::knit("Project1.Rmd")
